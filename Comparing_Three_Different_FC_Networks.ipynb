{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOD4dAmUAZ9OqUwLL+JbRoJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Alafiade/Comparing-Fully-Connected-Networks/blob/main/Comparing_Three_Different_FC_Networks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **COMPARISON BETWEEN THREE DIFFERENT FCN NETWORKS**"
      ],
      "metadata": {
        "id": "TrOZHN_F0W6u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "IMPORTING LIBRARIES"
      ],
      "metadata": {
        "id": "deokDSECyj6q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "5wEpxhsu3fuv"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torchvision import datasets\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.transforms import ToTensor\n",
        "from torch import nn"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "DOWNLOADING CIFAR 10 DATA"
      ],
      "metadata": {
        "id": "UfpM03zeyprl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = datasets.CIFAR10(\n",
        "    root='data',\n",
        "    train= True,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")\n",
        "\n",
        "test_data = datasets.CIFAR10(\n",
        "    root = 'data',\n",
        "    train = False,\n",
        "    download = True,\n",
        "    transform = ToTensor()\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_-AbwrHW4Ony",
        "outputId": "0867b624-2c1a-4c53-be62-c07ddee48c9a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:02<00:00, 61.2MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader =  DataLoader(train_data, batch_size = 64)\n",
        "test_loader = DataLoader(test_data, batch_size=64)"
      ],
      "metadata": {
        "id": "kHDzhn8Y5Ep4"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **BASE FCN ARCHITECTURE**"
      ],
      "metadata": {
        "id": "DQHfvx7_yuZI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNetwork(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.flatten = nn.Flatten()\n",
        "    self.linear_relu_stack = nn.Sequential(\n",
        "        nn.Linear(32*32 *3,128),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(128,64),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(64,32),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(32,10)\n",
        "    )\n",
        "\n",
        "  def forward(self,x):\n",
        "    x = self.flatten(x)\n",
        "    logits = self.linear_relu_stack(x)\n",
        "    return logits\n",
        "\n",
        "model = NeuralNetwork()\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "eioPyEVS5Vea"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "MODEL OPTIMIZATION"
      ],
      "metadata": {
        "id": "5F2x_QUryztb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_function = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "Lh5WYcJq7r8n"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.SGD(model.parameters(), lr= 1e3)"
      ],
      "metadata": {
        "id": "DcyK_2GH7z6B"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TRAINING AND TESTING OUR BASE FCN MODEL"
      ],
      "metadata": {
        "id": "0r8RBsFay6GW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_loop(model, loss_function, optimizer,train_loader, batch_size):\n",
        "  size = len(train_loader.dataset)\n",
        "  model.train()\n",
        "  for batch, (X,y) in enumerate(train_loader):\n",
        "    #computes our prediction and loss\n",
        "    pred = model(X)\n",
        "    loss = loss_function(pred,y)\n",
        "\n",
        "    #Back Propagation\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "\n",
        "    if batch % 100 == 0:\n",
        "      loss, current = loss.item(), batch * batch_size + len(X)\n",
        "      print(f'loss: {loss:>7f} [{current:>5d}/{size:>5d}]')\n",
        "\n",
        "def test_loop(dataloader, model, loss_fn):\n",
        "  model.eval()\n",
        "  size = len(dataloader.dataset)\n",
        "  num_batches = len(dataloader)\n",
        "  test_loss, correct = 0,0\n",
        "\n",
        "\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for X,  y in dataloader:\n",
        "      pred = model(X)\n",
        "      test_loss += loss_fn(pred,y).item()\n",
        "      correct += (pred.argmax(1)== y).type(torch.float).sum().item()\n",
        "\n",
        "  test_loss /= num_batches\n",
        "  correct /= size\n",
        "  print(f'Test Error:\\n Accuracy: {(100*correct): >0.1f}%, Avg loss: {test_loss:>8f} \\n')\n",
        "\n"
      ],
      "metadata": {
        "id": "s6qdI_vA8OXC"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_function =nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr= 1e-3)\n",
        "\n",
        "epochs = 20\n",
        "for t in range(epochs):\n",
        "  print(f'Epoch {t+1}\\n------------')\n",
        "  train_loop(model, loss_function, optimizer, train_loader, batch_size=64)\n",
        "  test_loop(test_loader, model,loss_function)\n",
        "print('Done')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aqN0f3Fn-kOh",
        "outputId": "fee54026-2c65-41b5-ff4a-931d9b58c3da"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "------------\n",
            "loss: 2.317958 [   64/50000]\n",
            "loss: 2.318170 [ 6464/50000]\n",
            "loss: 2.288847 [12864/50000]\n",
            "loss: 2.299459 [19264/50000]\n",
            "loss: 2.303936 [25664/50000]\n",
            "loss: 2.284413 [32064/50000]\n",
            "loss: 2.308548 [38464/50000]\n",
            "loss: 2.296699 [44864/50000]\n",
            "Test Error:\n",
            " Accuracy: 10.2%, Avg loss: 2.304459 \n",
            "\n",
            "Epoch 2\n",
            "------------\n",
            "loss: 2.313936 [   64/50000]\n",
            "loss: 2.313751 [ 6464/50000]\n",
            "loss: 2.288488 [12864/50000]\n",
            "loss: 2.295429 [19264/50000]\n",
            "loss: 2.299837 [25664/50000]\n",
            "loss: 2.283554 [32064/50000]\n",
            "loss: 2.306778 [38464/50000]\n",
            "loss: 2.293145 [44864/50000]\n",
            "Test Error:\n",
            " Accuracy: 12.4%, Avg loss: 2.301265 \n",
            "\n",
            "Epoch 3\n",
            "------------\n",
            "loss: 2.310834 [   64/50000]\n",
            "loss: 2.309862 [ 6464/50000]\n",
            "loss: 2.286298 [12864/50000]\n",
            "loss: 2.292904 [19264/50000]\n",
            "loss: 2.295994 [25664/50000]\n",
            "loss: 2.282023 [32064/50000]\n",
            "loss: 2.304715 [38464/50000]\n",
            "loss: 2.289515 [44864/50000]\n",
            "Test Error:\n",
            " Accuracy: 12.4%, Avg loss: 2.297798 \n",
            "\n",
            "Epoch 4\n",
            "------------\n",
            "loss: 2.308714 [   64/50000]\n",
            "loss: 2.305713 [ 6464/50000]\n",
            "loss: 2.282968 [12864/50000]\n",
            "loss: 2.290338 [19264/50000]\n",
            "loss: 2.292254 [25664/50000]\n",
            "loss: 2.279843 [32064/50000]\n",
            "loss: 2.302673 [38464/50000]\n",
            "loss: 2.285715 [44864/50000]\n",
            "Test Error:\n",
            " Accuracy: 12.4%, Avg loss: 2.294105 \n",
            "\n",
            "Epoch 5\n",
            "------------\n",
            "loss: 2.306565 [   64/50000]\n",
            "loss: 2.301268 [ 6464/50000]\n",
            "loss: 2.279245 [12864/50000]\n",
            "loss: 2.287196 [19264/50000]\n",
            "loss: 2.288129 [25664/50000]\n",
            "loss: 2.276764 [32064/50000]\n",
            "loss: 2.299878 [38464/50000]\n",
            "loss: 2.280913 [44864/50000]\n",
            "Test Error:\n",
            " Accuracy: 14.2%, Avg loss: 2.289687 \n",
            "\n",
            "Epoch 6\n",
            "------------\n",
            "loss: 2.303944 [   64/50000]\n",
            "loss: 2.296280 [ 6464/50000]\n",
            "loss: 2.274224 [12864/50000]\n",
            "loss: 2.283413 [19264/50000]\n",
            "loss: 2.282801 [25664/50000]\n",
            "loss: 2.272605 [32064/50000]\n",
            "loss: 2.295806 [38464/50000]\n",
            "loss: 2.274889 [44864/50000]\n",
            "Test Error:\n",
            " Accuracy: 15.7%, Avg loss: 2.284032 \n",
            "\n",
            "Epoch 7\n",
            "------------\n",
            "loss: 2.300918 [   64/50000]\n",
            "loss: 2.290404 [ 6464/50000]\n",
            "loss: 2.267540 [12864/50000]\n",
            "loss: 2.278381 [19264/50000]\n",
            "loss: 2.275909 [25664/50000]\n",
            "loss: 2.266294 [32064/50000]\n",
            "loss: 2.290307 [38464/50000]\n",
            "loss: 2.266562 [44864/50000]\n",
            "Test Error:\n",
            " Accuracy: 16.5%, Avg loss: 2.276313 \n",
            "\n",
            "Epoch 8\n",
            "------------\n",
            "loss: 2.296116 [   64/50000]\n",
            "loss: 2.282672 [ 6464/50000]\n",
            "loss: 2.258262 [12864/50000]\n",
            "loss: 2.271005 [19264/50000]\n",
            "loss: 2.266298 [25664/50000]\n",
            "loss: 2.257410 [32064/50000]\n",
            "loss: 2.282526 [38464/50000]\n",
            "loss: 2.254784 [44864/50000]\n",
            "Test Error:\n",
            " Accuracy: 16.8%, Avg loss: 2.264890 \n",
            "\n",
            "Epoch 9\n",
            "------------\n",
            "loss: 2.288787 [   64/50000]\n",
            "loss: 2.271323 [ 6464/50000]\n",
            "loss: 2.244936 [12864/50000]\n",
            "loss: 2.259196 [19264/50000]\n",
            "loss: 2.252883 [25664/50000]\n",
            "loss: 2.243870 [32064/50000]\n",
            "loss: 2.271546 [38464/50000]\n",
            "loss: 2.237197 [44864/50000]\n",
            "Test Error:\n",
            " Accuracy: 16.7%, Avg loss: 2.248030 \n",
            "\n",
            "Epoch 10\n",
            "------------\n",
            "loss: 2.278501 [   64/50000]\n",
            "loss: 2.254785 [ 6464/50000]\n",
            "loss: 2.225389 [12864/50000]\n",
            "loss: 2.242189 [19264/50000]\n",
            "loss: 2.234156 [25664/50000]\n",
            "loss: 2.223973 [32064/50000]\n",
            "loss: 2.256415 [38464/50000]\n",
            "loss: 2.211455 [44864/50000]\n",
            "Test Error:\n",
            " Accuracy: 16.7%, Avg loss: 2.223508 \n",
            "\n",
            "Epoch 11\n",
            "------------\n",
            "loss: 2.263242 [   64/50000]\n",
            "loss: 2.231642 [ 6464/50000]\n",
            "loss: 2.195267 [12864/50000]\n",
            "loss: 2.217957 [19264/50000]\n",
            "loss: 2.208215 [25664/50000]\n",
            "loss: 2.195039 [32064/50000]\n",
            "loss: 2.238411 [38464/50000]\n",
            "loss: 2.175257 [44864/50000]\n",
            "Test Error:\n",
            " Accuracy: 16.7%, Avg loss: 2.190548 \n",
            "\n",
            "Epoch 12\n",
            "------------\n",
            "loss: 2.240884 [   64/50000]\n",
            "loss: 2.201538 [ 6464/50000]\n",
            "loss: 2.154674 [12864/50000]\n",
            "loss: 2.188559 [19264/50000]\n",
            "loss: 2.178686 [25664/50000]\n",
            "loss: 2.161479 [32064/50000]\n",
            "loss: 2.222683 [38464/50000]\n",
            "loss: 2.131046 [44864/50000]\n",
            "Test Error:\n",
            " Accuracy: 17.3%, Avg loss: 2.152549 \n",
            "\n",
            "Epoch 13\n",
            "------------\n",
            "loss: 2.212337 [   64/50000]\n",
            "loss: 2.168229 [ 6464/50000]\n",
            "loss: 2.106044 [12864/50000]\n",
            "loss: 2.158912 [19264/50000]\n",
            "loss: 2.150416 [25664/50000]\n",
            "loss: 2.127405 [32064/50000]\n",
            "loss: 2.212193 [38464/50000]\n",
            "loss: 2.084774 [44864/50000]\n",
            "Test Error:\n",
            " Accuracy: 19.0%, Avg loss: 2.114808 \n",
            "\n",
            "Epoch 14\n",
            "------------\n",
            "loss: 2.180297 [   64/50000]\n",
            "loss: 2.137539 [ 6464/50000]\n",
            "loss: 2.054741 [12864/50000]\n",
            "loss: 2.132804 [19264/50000]\n",
            "loss: 2.129027 [25664/50000]\n",
            "loss: 2.098086 [32064/50000]\n",
            "loss: 2.204514 [38464/50000]\n",
            "loss: 2.043987 [44864/50000]\n",
            "Test Error:\n",
            " Accuracy: 20.5%, Avg loss: 2.081754 \n",
            "\n",
            "Epoch 15\n",
            "------------\n",
            "loss: 2.150531 [   64/50000]\n",
            "loss: 2.114473 [ 6464/50000]\n",
            "loss: 2.006224 [12864/50000]\n",
            "loss: 2.112252 [19264/50000]\n",
            "loss: 2.114920 [25664/50000]\n",
            "loss: 2.076712 [32064/50000]\n",
            "loss: 2.195248 [38464/50000]\n",
            "loss: 2.011601 [44864/50000]\n",
            "Test Error:\n",
            " Accuracy: 23.3%, Avg loss: 2.054518 \n",
            "\n",
            "Epoch 16\n",
            "------------\n",
            "loss: 2.127266 [   64/50000]\n",
            "loss: 2.098886 [ 6464/50000]\n",
            "loss: 1.962915 [12864/50000]\n",
            "loss: 2.094853 [19264/50000]\n",
            "loss: 2.104360 [25664/50000]\n",
            "loss: 2.064166 [32064/50000]\n",
            "loss: 2.181686 [38464/50000]\n",
            "loss: 1.989933 [44864/50000]\n",
            "Test Error:\n",
            " Accuracy: 24.7%, Avg loss: 2.032935 \n",
            "\n",
            "Epoch 17\n",
            "------------\n",
            "loss: 2.111740 [   64/50000]\n",
            "loss: 2.087628 [ 6464/50000]\n",
            "loss: 1.928915 [12864/50000]\n",
            "loss: 2.082692 [19264/50000]\n",
            "loss: 2.095316 [25664/50000]\n",
            "loss: 2.057661 [32064/50000]\n",
            "loss: 2.165449 [38464/50000]\n",
            "loss: 1.972593 [44864/50000]\n",
            "Test Error:\n",
            " Accuracy: 25.4%, Avg loss: 2.015450 \n",
            "\n",
            "Epoch 18\n",
            "------------\n",
            "loss: 2.101631 [   64/50000]\n",
            "loss: 2.077169 [ 6464/50000]\n",
            "loss: 1.902133 [12864/50000]\n",
            "loss: 2.073423 [19264/50000]\n",
            "loss: 2.084411 [25664/50000]\n",
            "loss: 2.052464 [32064/50000]\n",
            "loss: 2.149510 [38464/50000]\n",
            "loss: 1.957782 [44864/50000]\n",
            "Test Error:\n",
            " Accuracy: 26.1%, Avg loss: 2.000773 \n",
            "\n",
            "Epoch 19\n",
            "------------\n",
            "loss: 2.091939 [   64/50000]\n",
            "loss: 2.066011 [ 6464/50000]\n",
            "loss: 1.880115 [12864/50000]\n",
            "loss: 2.065717 [19264/50000]\n",
            "loss: 2.073478 [25664/50000]\n",
            "loss: 2.047677 [32064/50000]\n",
            "loss: 2.134161 [38464/50000]\n",
            "loss: 1.943304 [44864/50000]\n",
            "Test Error:\n",
            " Accuracy: 26.6%, Avg loss: 1.988020 \n",
            "\n",
            "Epoch 20\n",
            "------------\n",
            "loss: 2.083092 [   64/50000]\n",
            "loss: 2.054187 [ 6464/50000]\n",
            "loss: 1.862324 [12864/50000]\n",
            "loss: 2.057722 [19264/50000]\n",
            "loss: 2.062745 [25664/50000]\n",
            "loss: 2.042430 [32064/50000]\n",
            "loss: 2.119860 [38464/50000]\n",
            "loss: 1.929865 [44864/50000]\n",
            "Test Error:\n",
            " Accuracy: 27.0%, Avg loss: 1.976595 \n",
            "\n",
            "Done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **SHALLOW FCN (FCN2)**"
      ],
      "metadata": {
        "id": "sLCDGRmFzCjc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNetworkshallow(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.flatten = nn.Flatten()\n",
        "    self.linear_relu_stack = nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(32*32*3 ,64),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(64,32),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(32,10),\n",
        "\n",
        "\n",
        "    )\n",
        "\n",
        "  def forward(self,x):\n",
        "    x = self.flatten(x)\n",
        "    logits = self.linear_relu_stack(x)\n",
        "    return logits\n",
        "model_shallow = NeuralNetworkshallow()"
      ],
      "metadata": {
        "id": "8QEV3NEgodvI"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_function = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "JrJhiPGLqFDM"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.SGD(model_shallow.parameters(), lr=1e3)"
      ],
      "metadata": {
        "id": "DG1xo9RxqNdx"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_loop(model_shallow, loss_function, optimizer,train_loader, batch_size):\n",
        "  size = len(train_loader.dataset)\n",
        "  model_shallow.train()\n",
        "  for batch, (X,y) in enumerate(train_loader):\n",
        "    #computes our prediction and loss\n",
        "    pred = model_shallow(X)\n",
        "    loss = loss_function(pred,y)\n",
        "\n",
        "    #Back Propagation\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "\n",
        "    if batch % 100 == 0:\n",
        "      loss, current = loss.item(), batch * batch_size + len(X)\n",
        "      print(f'loss: {loss:>7f} [{current:>5d}/{size:>5d}]')\n",
        "\n",
        "def test_loop(dataloader, model_shallow, loss_fn):\n",
        "  model_shallow.eval()\n",
        "  size = len(dataloader.dataset)\n",
        "  num_batches = len(dataloader)\n",
        "  test_loss, correct = 0,0\n",
        "\n",
        "\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for X,  y in dataloader:\n",
        "      pred = model_shallow(X)\n",
        "      test_loss += loss_fn(pred,y).item()\n",
        "      correct += (pred.argmax(1)== y).type(torch.float).sum().item()\n",
        "\n",
        "  test_loss /= num_batches\n",
        "  correct /= size\n",
        "  print(f'Test Error:\\n Accuracy: {(100*correct): >0.1f}%, Avg loss: {test_loss:>8f} \\n')\n"
      ],
      "metadata": {
        "id": "kR1ZizUPqj3f"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_function =nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model_shallow.parameters(), lr= 1e-3)\n",
        "\n",
        "epochs = 20\n",
        "for t in range(epochs):\n",
        "  print(f'Epoch {t+1}\\n------------')\n",
        "  train_loop(model_shallow, loss_function, optimizer, train_loader, batch_size=64)\n",
        "  test_loop(test_loader, model_shallow,loss_function)\n",
        "print('Done')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "95e4jR75q4x6",
        "outputId": "abecb94f-f7b4-4e4d-8eb4-311b15f444fa"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "------------\n",
            "loss: 1.884628 [   64/50000]\n",
            "loss: 1.909518 [ 6464/50000]\n",
            "loss: 1.674149 [12864/50000]\n",
            "loss: 1.900882 [19264/50000]\n",
            "loss: 1.919927 [25664/50000]\n",
            "loss: 1.914465 [32064/50000]\n",
            "loss: 1.982248 [38464/50000]\n",
            "loss: 1.822044 [44864/50000]\n",
            "Test Error:\n",
            " Accuracy: 33.5%, Avg loss: 1.862310 \n",
            "\n",
            "Epoch 2\n",
            "------------\n",
            "loss: 1.870136 [   64/50000]\n",
            "loss: 1.896526 [ 6464/50000]\n",
            "loss: 1.660650 [12864/50000]\n",
            "loss: 1.892053 [19264/50000]\n",
            "loss: 1.913113 [25664/50000]\n",
            "loss: 1.908355 [32064/50000]\n",
            "loss: 1.975343 [38464/50000]\n",
            "loss: 1.812791 [44864/50000]\n",
            "Test Error:\n",
            " Accuracy: 33.7%, Avg loss: 1.855114 \n",
            "\n",
            "Epoch 3\n",
            "------------\n",
            "loss: 1.856190 [   64/50000]\n",
            "loss: 1.883604 [ 6464/50000]\n",
            "loss: 1.647446 [12864/50000]\n",
            "loss: 1.883265 [19264/50000]\n",
            "loss: 1.906451 [25664/50000]\n",
            "loss: 1.902214 [32064/50000]\n",
            "loss: 1.968389 [38464/50000]\n",
            "loss: 1.804066 [44864/50000]\n",
            "Test Error:\n",
            " Accuracy: 34.1%, Avg loss: 1.847996 \n",
            "\n",
            "Epoch 4\n",
            "------------\n",
            "loss: 1.841773 [   64/50000]\n",
            "loss: 1.870944 [ 6464/50000]\n",
            "loss: 1.634896 [12864/50000]\n",
            "loss: 1.875206 [19264/50000]\n",
            "loss: 1.900082 [25664/50000]\n",
            "loss: 1.896596 [32064/50000]\n",
            "loss: 1.961370 [38464/50000]\n",
            "loss: 1.795239 [44864/50000]\n",
            "Test Error:\n",
            " Accuracy: 34.3%, Avg loss: 1.841077 \n",
            "\n",
            "Epoch 5\n",
            "------------\n",
            "loss: 1.828273 [   64/50000]\n",
            "loss: 1.858144 [ 6464/50000]\n",
            "loss: 1.622212 [12864/50000]\n",
            "loss: 1.867199 [19264/50000]\n",
            "loss: 1.893369 [25664/50000]\n",
            "loss: 1.890723 [32064/50000]\n",
            "loss: 1.954864 [38464/50000]\n",
            "loss: 1.786362 [44864/50000]\n",
            "Test Error:\n",
            " Accuracy: 34.6%, Avg loss: 1.834257 \n",
            "\n",
            "Epoch 6\n",
            "------------\n",
            "loss: 1.814872 [   64/50000]\n",
            "loss: 1.845690 [ 6464/50000]\n",
            "loss: 1.610089 [12864/50000]\n",
            "loss: 1.858751 [19264/50000]\n",
            "loss: 1.886952 [25664/50000]\n",
            "loss: 1.883904 [32064/50000]\n",
            "loss: 1.948196 [38464/50000]\n",
            "loss: 1.777750 [44864/50000]\n",
            "Test Error:\n",
            " Accuracy: 34.8%, Avg loss: 1.827493 \n",
            "\n",
            "Epoch 7\n",
            "------------\n",
            "loss: 1.802052 [   64/50000]\n",
            "loss: 1.833391 [ 6464/50000]\n",
            "loss: 1.598144 [12864/50000]\n",
            "loss: 1.849983 [19264/50000]\n",
            "loss: 1.880182 [25664/50000]\n",
            "loss: 1.877335 [32064/50000]\n",
            "loss: 1.942137 [38464/50000]\n",
            "loss: 1.768753 [44864/50000]\n",
            "Test Error:\n",
            " Accuracy: 34.9%, Avg loss: 1.820884 \n",
            "\n",
            "Epoch 8\n",
            "------------\n",
            "loss: 1.790198 [   64/50000]\n",
            "loss: 1.821579 [ 6464/50000]\n",
            "loss: 1.586537 [12864/50000]\n",
            "loss: 1.842151 [19264/50000]\n",
            "loss: 1.873939 [25664/50000]\n",
            "loss: 1.870965 [32064/50000]\n",
            "loss: 1.935922 [38464/50000]\n",
            "loss: 1.759673 [44864/50000]\n",
            "Test Error:\n",
            " Accuracy: 35.3%, Avg loss: 1.814368 \n",
            "\n",
            "Epoch 9\n",
            "------------\n",
            "loss: 1.778925 [   64/50000]\n",
            "loss: 1.810423 [ 6464/50000]\n",
            "loss: 1.575182 [12864/50000]\n",
            "loss: 1.834842 [19264/50000]\n",
            "loss: 1.867484 [25664/50000]\n",
            "loss: 1.864854 [32064/50000]\n",
            "loss: 1.929597 [38464/50000]\n",
            "loss: 1.750601 [44864/50000]\n",
            "Test Error:\n",
            " Accuracy: 35.5%, Avg loss: 1.807891 \n",
            "\n",
            "Epoch 10\n",
            "------------\n",
            "loss: 1.768671 [   64/50000]\n",
            "loss: 1.800022 [ 6464/50000]\n",
            "loss: 1.564302 [12864/50000]\n",
            "loss: 1.826841 [19264/50000]\n",
            "loss: 1.861069 [25664/50000]\n",
            "loss: 1.857963 [32064/50000]\n",
            "loss: 1.922892 [38464/50000]\n",
            "loss: 1.741252 [44864/50000]\n",
            "Test Error:\n",
            " Accuracy: 35.8%, Avg loss: 1.801559 \n",
            "\n",
            "Epoch 11\n",
            "------------\n",
            "loss: 1.759106 [   64/50000]\n",
            "loss: 1.789442 [ 6464/50000]\n",
            "loss: 1.553918 [12864/50000]\n",
            "loss: 1.818126 [19264/50000]\n",
            "loss: 1.854351 [25664/50000]\n",
            "loss: 1.851120 [32064/50000]\n",
            "loss: 1.916697 [38464/50000]\n",
            "loss: 1.731483 [44864/50000]\n",
            "Test Error:\n",
            " Accuracy: 36.1%, Avg loss: 1.795359 \n",
            "\n",
            "Epoch 12\n",
            "------------\n",
            "loss: 1.750160 [   64/50000]\n",
            "loss: 1.779435 [ 6464/50000]\n",
            "loss: 1.543308 [12864/50000]\n",
            "loss: 1.810031 [19264/50000]\n",
            "loss: 1.847710 [25664/50000]\n",
            "loss: 1.844226 [32064/50000]\n",
            "loss: 1.910190 [38464/50000]\n",
            "loss: 1.721942 [44864/50000]\n",
            "Test Error:\n",
            " Accuracy: 36.2%, Avg loss: 1.789274 \n",
            "\n",
            "Epoch 13\n",
            "------------\n",
            "loss: 1.742128 [   64/50000]\n",
            "loss: 1.769858 [ 6464/50000]\n",
            "loss: 1.533222 [12864/50000]\n",
            "loss: 1.801607 [19264/50000]\n",
            "loss: 1.840960 [25664/50000]\n",
            "loss: 1.837921 [32064/50000]\n",
            "loss: 1.904087 [38464/50000]\n",
            "loss: 1.713000 [44864/50000]\n",
            "Test Error:\n",
            " Accuracy: 36.4%, Avg loss: 1.783162 \n",
            "\n",
            "Epoch 14\n",
            "------------\n",
            "loss: 1.735081 [   64/50000]\n",
            "loss: 1.760661 [ 6464/50000]\n",
            "loss: 1.524123 [12864/50000]\n",
            "loss: 1.793303 [19264/50000]\n",
            "loss: 1.833897 [25664/50000]\n",
            "loss: 1.831448 [32064/50000]\n",
            "loss: 1.898058 [38464/50000]\n",
            "loss: 1.703828 [44864/50000]\n",
            "Test Error:\n",
            " Accuracy: 36.8%, Avg loss: 1.777007 \n",
            "\n",
            "Epoch 15\n",
            "------------\n",
            "loss: 1.727412 [   64/50000]\n",
            "loss: 1.752104 [ 6464/50000]\n",
            "loss: 1.515613 [12864/50000]\n",
            "loss: 1.784664 [19264/50000]\n",
            "loss: 1.827055 [25664/50000]\n",
            "loss: 1.826017 [32064/50000]\n",
            "loss: 1.892650 [38464/50000]\n",
            "loss: 1.694669 [44864/50000]\n",
            "Test Error:\n",
            " Accuracy: 37.1%, Avg loss: 1.771223 \n",
            "\n",
            "Epoch 16\n",
            "------------\n",
            "loss: 1.720726 [   64/50000]\n",
            "loss: 1.743632 [ 6464/50000]\n",
            "loss: 1.507436 [12864/50000]\n",
            "loss: 1.776657 [19264/50000]\n",
            "loss: 1.820008 [25664/50000]\n",
            "loss: 1.821567 [32064/50000]\n",
            "loss: 1.886470 [38464/50000]\n",
            "loss: 1.686647 [44864/50000]\n",
            "Test Error:\n",
            " Accuracy: 37.4%, Avg loss: 1.765447 \n",
            "\n",
            "Epoch 17\n",
            "------------\n",
            "loss: 1.713743 [   64/50000]\n",
            "loss: 1.735532 [ 6464/50000]\n",
            "loss: 1.499300 [12864/50000]\n",
            "loss: 1.769026 [19264/50000]\n",
            "loss: 1.813384 [25664/50000]\n",
            "loss: 1.817752 [32064/50000]\n",
            "loss: 1.880664 [38464/50000]\n",
            "loss: 1.679364 [44864/50000]\n",
            "Test Error:\n",
            " Accuracy: 37.5%, Avg loss: 1.759819 \n",
            "\n",
            "Epoch 18\n",
            "------------\n",
            "loss: 1.708151 [   64/50000]\n",
            "loss: 1.727810 [ 6464/50000]\n",
            "loss: 1.491553 [12864/50000]\n",
            "loss: 1.761560 [19264/50000]\n",
            "loss: 1.807194 [25664/50000]\n",
            "loss: 1.814398 [32064/50000]\n",
            "loss: 1.874674 [38464/50000]\n",
            "loss: 1.671817 [44864/50000]\n",
            "Test Error:\n",
            " Accuracy: 37.5%, Avg loss: 1.754373 \n",
            "\n",
            "Epoch 19\n",
            "------------\n",
            "loss: 1.702597 [   64/50000]\n",
            "loss: 1.720335 [ 6464/50000]\n",
            "loss: 1.484482 [12864/50000]\n",
            "loss: 1.754253 [19264/50000]\n",
            "loss: 1.800514 [25664/50000]\n",
            "loss: 1.810516 [32064/50000]\n",
            "loss: 1.868033 [38464/50000]\n",
            "loss: 1.665167 [44864/50000]\n",
            "Test Error:\n",
            " Accuracy: 37.7%, Avg loss: 1.748935 \n",
            "\n",
            "Epoch 20\n",
            "------------\n",
            "loss: 1.696962 [   64/50000]\n",
            "loss: 1.713688 [ 6464/50000]\n",
            "loss: 1.476947 [12864/50000]\n",
            "loss: 1.746840 [19264/50000]\n",
            "loss: 1.794388 [25664/50000]\n",
            "loss: 1.806750 [32064/50000]\n",
            "loss: 1.861416 [38464/50000]\n",
            "loss: 1.659179 [44864/50000]\n",
            "Test Error:\n",
            " Accuracy: 38.0%, Avg loss: 1.743559 \n",
            "\n",
            "Done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **DEEP FCN (FCN3)**"
      ],
      "metadata": {
        "id": "flURjsaVzLy4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "8gvAN1RrzLqe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNetwork_deep(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.flatten = nn.Flatten()\n",
        "    self.linear_relu_stack = nn.Sequential(\n",
        "        nn.Linear(32*32 *3,512),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(512,256),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(256,128),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(128,10)\n",
        "    )\n",
        "\n",
        "  def forward(self,x):\n",
        "    x = self.flatten(x)\n",
        "    logits = self.linear_relu_stack(x)\n",
        "    return logits\n",
        "\n",
        "model_deep = NeuralNetwork()"
      ],
      "metadata": {
        "id": "hSwNpvq7ruCX"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_function = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "aoIG37OzsQg7"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer_deep = torch.optim.SGD(model_deep.parameters(),lr = 1e3)"
      ],
      "metadata": {
        "id": "_ifKmlvCsVYj"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_loop(model_deep, loss_function, optimizer,train_loader, batch_size):\n",
        "  size = len(train_loader.dataset)\n",
        "  model_deep.train()\n",
        "  for batch, (X,y) in enumerate(train_loader):\n",
        "    #computes our prediction and loss\n",
        "    pred = model_deep(X)\n",
        "    loss = loss_function(pred,y)\n",
        "\n",
        "    #Back Propagation\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "\n",
        "    if batch % 100 == 0:\n",
        "      loss, current = loss.item(), batch * batch_size + len(X)\n",
        "      print(f'loss: {loss:>7f} [{current:>5d}/{size:>5d}]')\n",
        "\n",
        "def test_loop(test_loader, model_deep, loss_function):\n",
        "  model_deep.eval()\n",
        "  size = len(test_loader.dataset)\n",
        "  num_batches = len(test_loader)\n",
        "  test_loss, correct = 0,0\n",
        "\n",
        "\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for X,  y in test_loader:\n",
        "      pred = model_deep(X)\n",
        "      test_loss += loss_function(pred,y).item()\n",
        "      correct += (pred.argmax(1)== y).type(torch.float).sum().item()\n",
        "\n",
        "  test_loss /= num_batches\n",
        "  correct /= size\n",
        "  print(f'Test Error:\\n Accuracy: {(100*correct): >0.1f}%, Avg loss: {test_loss:>8f} \\n')\n"
      ],
      "metadata": {
        "id": "klnNwuXtsqTu"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_function =nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model_deep.parameters(), lr= 1e-3)\n",
        "\n",
        "epochs = 20\n",
        "for t in range(epochs):\n",
        "  print(f'Epoch {t+1}\\n------------')\n",
        "  train_loop(model_deep, loss_function, optimizer, train_loader, batch_size=64)\n",
        "  test_loop(test_loader, model_deep,loss_function)\n",
        "print('Done')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7jEldE3ftPIa",
        "outputId": "cd3251d0-832c-411d-a7f7-06f5d2b16db7"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "------------\n",
            "loss: 2.291518 [   64/50000]\n",
            "loss: 2.298073 [ 6464/50000]\n",
            "loss: 2.316095 [12864/50000]\n",
            "loss: 2.307825 [19264/50000]\n",
            "loss: 2.295567 [25664/50000]\n",
            "loss: 2.313793 [32064/50000]\n",
            "loss: 2.307468 [38464/50000]\n",
            "loss: 2.294712 [44864/50000]\n",
            "Test Error:\n",
            " Accuracy: 10.2%, Avg loss: 2.301805 \n",
            "\n",
            "Epoch 2\n",
            "------------\n",
            "loss: 2.292271 [   64/50000]\n",
            "loss: 2.296437 [ 6464/50000]\n",
            "loss: 2.309997 [12864/50000]\n",
            "loss: 2.301377 [19264/50000]\n",
            "loss: 2.291864 [25664/50000]\n",
            "loss: 2.307899 [32064/50000]\n",
            "loss: 2.303681 [38464/50000]\n",
            "loss: 2.293417 [44864/50000]\n",
            "Test Error:\n",
            " Accuracy: 12.2%, Avg loss: 2.298299 \n",
            "\n",
            "Epoch 3\n",
            "------------\n",
            "loss: 2.291390 [   64/50000]\n",
            "loss: 2.295190 [ 6464/50000]\n",
            "loss: 2.304945 [12864/50000]\n",
            "loss: 2.296865 [19264/50000]\n",
            "loss: 2.288312 [25664/50000]\n",
            "loss: 2.302827 [32064/50000]\n",
            "loss: 2.299927 [38464/50000]\n",
            "loss: 2.291979 [44864/50000]\n",
            "Test Error:\n",
            " Accuracy: 13.6%, Avg loss: 2.294935 \n",
            "\n",
            "Epoch 4\n",
            "------------\n",
            "loss: 2.290711 [   64/50000]\n",
            "loss: 2.293509 [ 6464/50000]\n",
            "loss: 2.299581 [12864/50000]\n",
            "loss: 2.292522 [19264/50000]\n",
            "loss: 2.284115 [25664/50000]\n",
            "loss: 2.297312 [32064/50000]\n",
            "loss: 2.295019 [38464/50000]\n",
            "loss: 2.289424 [44864/50000]\n",
            "Test Error:\n",
            " Accuracy: 15.4%, Avg loss: 2.290684 \n",
            "\n",
            "Epoch 5\n",
            "------------\n",
            "loss: 2.289974 [   64/50000]\n",
            "loss: 2.291595 [ 6464/50000]\n",
            "loss: 2.291345 [12864/50000]\n",
            "loss: 2.286181 [19264/50000]\n",
            "loss: 2.279124 [25664/50000]\n",
            "loss: 2.289598 [32064/50000]\n",
            "loss: 2.286792 [38464/50000]\n",
            "loss: 2.286315 [44864/50000]\n",
            "Test Error:\n",
            " Accuracy: 18.3%, Avg loss: 2.284326 \n",
            "\n",
            "Epoch 6\n",
            "------------\n",
            "loss: 2.289313 [   64/50000]\n",
            "loss: 2.289290 [ 6464/50000]\n",
            "loss: 2.279250 [12864/50000]\n",
            "loss: 2.280230 [19264/50000]\n",
            "loss: 2.271565 [25664/50000]\n",
            "loss: 2.280426 [32064/50000]\n",
            "loss: 2.276954 [38464/50000]\n",
            "loss: 2.281386 [44864/50000]\n",
            "Test Error:\n",
            " Accuracy: 18.2%, Avg loss: 2.275541 \n",
            "\n",
            "Epoch 7\n",
            "------------\n",
            "loss: 2.287265 [   64/50000]\n",
            "loss: 2.284724 [ 6464/50000]\n",
            "loss: 2.260918 [12864/50000]\n",
            "loss: 2.273303 [19264/50000]\n",
            "loss: 2.258728 [25664/50000]\n",
            "loss: 2.267095 [32064/50000]\n",
            "loss: 2.262077 [38464/50000]\n",
            "loss: 2.271007 [44864/50000]\n",
            "Test Error:\n",
            " Accuracy: 18.0%, Avg loss: 2.262534 \n",
            "\n",
            "Epoch 8\n",
            "------------\n",
            "loss: 2.283320 [   64/50000]\n",
            "loss: 2.276491 [ 6464/50000]\n",
            "loss: 2.236591 [12864/50000]\n",
            "loss: 2.265634 [19264/50000]\n",
            "loss: 2.242961 [25664/50000]\n",
            "loss: 2.252055 [32064/50000]\n",
            "loss: 2.246423 [38464/50000]\n",
            "loss: 2.257797 [44864/50000]\n",
            "Test Error:\n",
            " Accuracy: 18.7%, Avg loss: 2.246328 \n",
            "\n",
            "Epoch 9\n",
            "------------\n",
            "loss: 2.276735 [   64/50000]\n",
            "loss: 2.263426 [ 6464/50000]\n",
            "loss: 2.210200 [12864/50000]\n",
            "loss: 2.252409 [19264/50000]\n",
            "loss: 2.223553 [25664/50000]\n",
            "loss: 2.232487 [32064/50000]\n",
            "loss: 2.228162 [38464/50000]\n",
            "loss: 2.237071 [44864/50000]\n",
            "Test Error:\n",
            " Accuracy: 18.8%, Avg loss: 2.224619 \n",
            "\n",
            "Epoch 10\n",
            "------------\n",
            "loss: 2.267243 [   64/50000]\n",
            "loss: 2.246028 [ 6464/50000]\n",
            "loss: 2.176804 [12864/50000]\n",
            "loss: 2.232801 [19264/50000]\n",
            "loss: 2.199742 [25664/50000]\n",
            "loss: 2.205933 [32064/50000]\n",
            "loss: 2.207663 [38464/50000]\n",
            "loss: 2.210955 [44864/50000]\n",
            "Test Error:\n",
            " Accuracy: 19.8%, Avg loss: 2.197866 \n",
            "\n",
            "Epoch 11\n",
            "------------\n",
            "loss: 2.254944 [   64/50000]\n",
            "loss: 2.224238 [ 6464/50000]\n",
            "loss: 2.137697 [12864/50000]\n",
            "loss: 2.208200 [19264/50000]\n",
            "loss: 2.172303 [25664/50000]\n",
            "loss: 2.175919 [32064/50000]\n",
            "loss: 2.187879 [38464/50000]\n",
            "loss: 2.177862 [44864/50000]\n",
            "Test Error:\n",
            " Accuracy: 20.3%, Avg loss: 2.167509 \n",
            "\n",
            "Epoch 12\n",
            "------------\n",
            "loss: 2.240095 [   64/50000]\n",
            "loss: 2.199613 [ 6464/50000]\n",
            "loss: 2.094237 [12864/50000]\n",
            "loss: 2.179856 [19264/50000]\n",
            "loss: 2.142172 [25664/50000]\n",
            "loss: 2.143795 [32064/50000]\n",
            "loss: 2.171179 [38464/50000]\n",
            "loss: 2.139427 [44864/50000]\n",
            "Test Error:\n",
            " Accuracy: 21.3%, Avg loss: 2.133380 \n",
            "\n",
            "Epoch 13\n",
            "------------\n",
            "loss: 2.223162 [   64/50000]\n",
            "loss: 2.171454 [ 6464/50000]\n",
            "loss: 2.044905 [12864/50000]\n",
            "loss: 2.147146 [19264/50000]\n",
            "loss: 2.110258 [25664/50000]\n",
            "loss: 2.110628 [32064/50000]\n",
            "loss: 2.158156 [38464/50000]\n",
            "loss: 2.097142 [44864/50000]\n",
            "Test Error:\n",
            " Accuracy: 22.6%, Avg loss: 2.099433 \n",
            "\n",
            "Epoch 14\n",
            "------------\n",
            "loss: 2.202514 [   64/50000]\n",
            "loss: 2.143546 [ 6464/50000]\n",
            "loss: 1.996056 [12864/50000]\n",
            "loss: 2.115848 [19264/50000]\n",
            "loss: 2.081610 [25664/50000]\n",
            "loss: 2.081560 [32064/50000]\n",
            "loss: 2.150150 [38464/50000]\n",
            "loss: 2.055329 [44864/50000]\n",
            "Test Error:\n",
            " Accuracy: 23.4%, Avg loss: 2.065777 \n",
            "\n",
            "Epoch 15\n",
            "------------\n",
            "loss: 2.180354 [   64/50000]\n",
            "loss: 2.118323 [ 6464/50000]\n",
            "loss: 1.945812 [12864/50000]\n",
            "loss: 2.094181 [19264/50000]\n",
            "loss: 2.054618 [25664/50000]\n",
            "loss: 2.060869 [32064/50000]\n",
            "loss: 2.143265 [38464/50000]\n",
            "loss: 2.025009 [44864/50000]\n",
            "Test Error:\n",
            " Accuracy: 23.9%, Avg loss: 2.038422 \n",
            "\n",
            "Epoch 16\n",
            "------------\n",
            "loss: 2.159808 [   64/50000]\n",
            "loss: 2.097498 [ 6464/50000]\n",
            "loss: 1.909512 [12864/50000]\n",
            "loss: 2.078813 [19264/50000]\n",
            "loss: 2.036948 [25664/50000]\n",
            "loss: 2.049783 [32064/50000]\n",
            "loss: 2.132789 [38464/50000]\n",
            "loss: 2.001426 [44864/50000]\n",
            "Test Error:\n",
            " Accuracy: 24.9%, Avg loss: 2.017670 \n",
            "\n",
            "Epoch 17\n",
            "------------\n",
            "loss: 2.146322 [   64/50000]\n",
            "loss: 2.080512 [ 6464/50000]\n",
            "loss: 1.882795 [12864/50000]\n",
            "loss: 2.068683 [19264/50000]\n",
            "loss: 2.024929 [25664/50000]\n",
            "loss: 2.043014 [32064/50000]\n",
            "loss: 2.121325 [38464/50000]\n",
            "loss: 1.981913 [44864/50000]\n",
            "Test Error:\n",
            " Accuracy: 26.1%, Avg loss: 2.001448 \n",
            "\n",
            "Epoch 18\n",
            "------------\n",
            "loss: 2.134894 [   64/50000]\n",
            "loss: 2.066679 [ 6464/50000]\n",
            "loss: 1.863116 [12864/50000]\n",
            "loss: 2.061149 [19264/50000]\n",
            "loss: 2.015445 [25664/50000]\n",
            "loss: 2.038138 [32064/50000]\n",
            "loss: 2.109451 [38464/50000]\n",
            "loss: 1.964042 [44864/50000]\n",
            "Test Error:\n",
            " Accuracy: 27.0%, Avg loss: 1.988071 \n",
            "\n",
            "Epoch 19\n",
            "------------\n",
            "loss: 2.123524 [   64/50000]\n",
            "loss: 2.054552 [ 6464/50000]\n",
            "loss: 1.848341 [12864/50000]\n",
            "loss: 2.053642 [19264/50000]\n",
            "loss: 2.007726 [25664/50000]\n",
            "loss: 2.033942 [32064/50000]\n",
            "loss: 2.098031 [38464/50000]\n",
            "loss: 1.947819 [44864/50000]\n",
            "Test Error:\n",
            " Accuracy: 27.6%, Avg loss: 1.976389 \n",
            "\n",
            "Epoch 20\n",
            "------------\n",
            "loss: 2.111314 [   64/50000]\n",
            "loss: 2.043536 [ 6464/50000]\n",
            "loss: 1.836433 [12864/50000]\n",
            "loss: 2.044864 [19264/50000]\n",
            "loss: 2.000469 [25664/50000]\n",
            "loss: 2.030142 [32064/50000]\n",
            "loss: 2.087157 [38464/50000]\n",
            "loss: 1.933124 [44864/50000]\n",
            "Test Error:\n",
            " Accuracy: 28.1%, Avg loss: 1.965792 \n",
            "\n",
            "Done\n"
          ]
        }
      ]
    }
  ]
}